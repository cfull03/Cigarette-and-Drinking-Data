{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be31be31",
   "metadata": {},
   "source": [
    "# Cell 1 — Title & Metadata (Markdown)\n",
    "\n",
    "# 0.1 — EDA & Feature Engineering (config-driven)\n",
    "\n",
    "**Goal:** config-driven EDA and light feature engineering for modeling readiness.\n",
    "\n",
    "**Config:** `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, re, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load config\n",
    "PROJECT_DIR = Path.cwd().resolve().parent if Path.cwd().name == \"notebooks\" else Path.cwd().resolve()\n",
    "CFG_PATH = PROJECT_DIR / \"config\" / \"config.yaml\"\n",
    "assert CFG_PATH.exists(), f\"Config not found: {CFG_PATH}\"\n",
    "with CFG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "# Seed\n",
    "SEED = int(CFG.get(\"project\", {}).get(\"seed\", 42))\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "pd.options.display.max_columns = 120\n",
    "pd.options.display.width = 160\n",
    "\n",
    "CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = CFG.get(\"paths\", {})\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "RAW_CSV = PROJECT_DIR / paths.get(\"raw_csv\", \"data/raw/addiction_population_data.csv\")\n",
    "PROCESSED_DIR = PROJECT_DIR / paths.get(\"processed_dir\", \"data/processed\")\n",
    "REPORTS_DIR = PROJECT_DIR / paths.get(\"reports_dir\", \"reports\")\n",
    "ARTIFACTS_DIR = PROJECT_DIR / paths.get(\"artifacts_dir\", \"artifacts\")\n",
    "SCHEMA_PATH = paths.get(\"schema\") and (PROJECT_DIR / paths[\"schema\"]) or None\n",
    "\n",
    "FIG_DIR = REPORTS_DIR / \"figures\" / \"0_1_eda\"\n",
    "for p in (PROCESSED_DIR, REPORTS_DIR, ARTIFACTS_DIR, FIG_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_opts = CFG.get(\"csv_options\", {})\n",
    "sep = csv_opts.get(\"sep\", \",\")\n",
    "header = csv_opts.get(\"header\", 0)\n",
    "encoding = csv_opts.get(\"encoding\", \"utf-8\")\n",
    "na_values = csv_opts.get(\"na_values\", [\"\", \"NA\", \"NaN\", \"null\"])\n",
    "cfg_parse_dates = csv_opts.get(\"parse_dates\", []) or None\n",
    "cfg_dtype = csv_opts.get(\"dtype\", {}) or {}\n",
    "\n",
    "# Align dtype keys with existing columns to avoid KeyErrors\n",
    "if RAW_CSV.exists():\n",
    "    preview_cols = pd.read_csv(RAW_CSV, nrows=0, sep=sep, encoding=encoding).columns\n",
    "    dtype_filtered = {k: v for k, v in cfg_dtype.items() if k in preview_cols}\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Raw CSV not found: {RAW_CSV}\")\n",
    "\n",
    "# Pandas dtype mapping normalization\n",
    "dtype_map = {\n",
    "    \"int8\": \"Int8\", \"int16\": \"Int16\", \"int32\": \"Int32\", \"int64\": \"Int64\",\n",
    "    \"float32\": \"Float32\", \"float64\": \"Float64\",\n",
    "    \"boolean\": \"boolean\", \"category\": \"category\", \"string\": \"string\"\n",
    "}\n",
    "for k, v in list(dtype_filtered.items()):\n",
    "    dtype_filtered[k] = dtype_map.get(str(v).lower(), v)\n",
    "\n",
    "df = pd.read_csv(\n",
    "    RAW_CSV,\n",
    "    sep=sep,\n",
    "    header=header,\n",
    "    encoding=encoding,\n",
    "    na_values=na_values,\n",
    "    dtype=dtype_filtered if dtype_filtered else None,\n",
    "    parse_dates=cfg_parse_dates\n",
    ")\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(f\"Loaded: {RAW_CSV} -> {rows} x {cols}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates_best_effort(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if CFG.get(\"csv_options\", {}).get(\"parse_dates\"):\n",
    "        return df\n",
    "    date_like = [c for c in df.columns if re.search(r\"(date|dt|time|year|month)\", str(c), re.I)]\n",
    "    for c in date_like:\n",
    "        try:\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"ignore\", infer_datetime_format=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "def summarize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nunique = df.nunique(dropna=False)\n",
    "    missing = df.isna().mean()\n",
    "    dtypes = df.dtypes.astype(str)\n",
    "    ex = df.head(1).transpose()[0].astype(str)\n",
    "    return (pd.DataFrame({\n",
    "        \"dtype\": dtypes,\n",
    "        \"n_unique\": nunique,\n",
    "        \"missing_pct\": (missing * 100).round(2),\n",
    "        \"example\": ex\n",
    "    }).reset_index(names=\"column\").sort_values([\"dtype\", \"column\"]).reset_index(drop=True))\n",
    "\n",
    "def numeric_and_categorical(df: pd.DataFrame, max_unique_for_cat: int = 20):\n",
    "    num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    low_card_num = [c for c in num if df[c].nunique(dropna=True) <= max_unique_for_cat]\n",
    "    cats = list(df.columns.difference(num)) + low_card_num\n",
    "    seen = set(); cats = [c for c in cats if (c not in seen) and (not seen.add(c))]\n",
    "    num_true = [c for c in num if c not in low_card_num]\n",
    "    return num_true, cats\n",
    "\n",
    "def safe_series(x: pd.Series) -> pd.Series:\n",
    "    return x.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def winsorize_series(s: pd.Series, lower=0.005, upper=0.995) -> pd.Series:\n",
    "    if s.notna().sum() < 10:\n",
    "        return s\n",
    "    return s.clip(lower=s.quantile(lower), upper=s.quantile(upper))\n",
    "\n",
    "def detect_population_col(df: pd.DataFrame):\n",
    "    cands = [c for c in df.columns if re.search(r\"pop|population\", str(c), re.I)]\n",
    "    if \"population\" in df.columns:\n",
    "        return \"population\"\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "def detect_count_cols(df: pd.DataFrame):\n",
    "    return [c for c in df.columns if re.search(r\"(count|cases?|deaths?|events?)\", str(c), re.I)\n",
    "            and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def detect_gender_cols(df: pd.DataFrame):\n",
    "    male = [c for c in df.columns if re.search(r\"\\bmale\\b|_m(ale)?\\b\", str(c), re.I)]\n",
    "    female = [c for c in df.columns if re.search(r\"\\bfemale\\b|_f(emale)?\\b\", str(c), re.I)]\n",
    "    return male, female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23919427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_dates_best_effort(df)\n",
    "schema = summarize(df)\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "schema.head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols, cat_cols = numeric_and_categorical(df)\n",
    "print(f\"Numeric: {len(num_cols)} | Categorical/low-card: {len(cat_cols)}\")\n",
    "(num_cols[:8], cat_cols[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_histograms(df, cols, limit=12):\n",
    "    for col in cols[:limit]:\n",
    "        fig = plt.figure()\n",
    "        safe_series(df[col]).dropna().hist(bins=30)\n",
    "        plt.title(f\"Histogram: {col}\")\n",
    "        plt.xlabel(col); plt.ylabel(\"Frequency\")\n",
    "        plt.savefig(FIG_DIR / f\"hist_{col}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "def save_boxplots(df, cols, limit=10):\n",
    "    for col in cols[:limit]:\n",
    "        fig = plt.figure()\n",
    "        plt.boxplot(safe_series(df[col]).dropna(), vert=True, labels=[col])\n",
    "        plt.title(f\"Boxplot: {col}\")\n",
    "        plt.savefig(FIG_DIR / f\"box_{col}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "def save_bar_small_cats(df, cats, limit=10, max_unique=20):\n",
    "    small = [c for c in cats if df[c].nunique(dropna=True) <= max_unique][:limit]\n",
    "    for col in small:\n",
    "        counts = df[col].astype(str).fillna(\"NA\").value_counts()\n",
    "        fig = plt.figure()\n",
    "        counts.plot(kind=\"bar\")\n",
    "        plt.title(f\"Counts: {col}\")\n",
    "        plt.xlabel(col); plt.ylabel(\"Count\")\n",
    "        plt.savefig(FIG_DIR / f\"bar_{col}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "def save_corr_heatmap(df, num_cols):\n",
    "    if len(num_cols) < 2:\n",
    "        return None\n",
    "    corr = df[num_cols].corr(numeric_only=True)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(corr, aspect=\"auto\")\n",
    "    plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
    "    plt.yticks(range(len(num_cols)), num_cols)\n",
    "    plt.title(\"Correlation (Pearson)\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / \"corr_heatmap.png\"\n",
    "    plt.savefig(out, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return out\n",
    "\n",
    "save_histograms(df, num_cols)\n",
    "save_boxplots(df, num_cols)\n",
    "save_bar_small_cats(df, cat_cols)\n",
    "corr_path = save_corr_heatmap(df, num_cols)\n",
    "sorted([p.name for p in FIG_DIR.glob(\"*.png\")])[:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df.copy()\n",
    "created_cols = []\n",
    "\n",
    "# Per-capita rates\n",
    "pop_col = detect_population_col(df_feat)\n",
    "if pop_col and pd.api.types.is_numeric_dtype(df_feat[pop_col]):\n",
    "    for c in detect_count_cols(df_feat):\n",
    "        rate_col = f\"{c}_per_100k\"\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            df_feat[rate_col] = (df_feat[c] / df_feat[pop_col]) * 1e5\n",
    "        df_feat[rate_col] = safe_series(df_feat[rate_col])\n",
    "        created_cols.append(rate_col)\n",
    "\n",
    "# Gender proportions\n",
    "male_cols, female_cols = detect_gender_cols(df_feat)\n",
    "if male_cols and female_cols:\n",
    "    mcol, fcol = male_cols[0], female_cols[0]\n",
    "    total_col = f\"{mcol}_plus_{fcol}_total\"\n",
    "    df_feat[total_col] = safe_series(df_feat[mcol]) + safe_series(df_feat[fcol])\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        df_feat[f\"prop_{mcol}\"] = safe_series(df_feat[mcol]) / df_feat[total_col]\n",
    "        df_feat[f\"prop_{fcol}\"] = safe_series(df_feat[fcol]) / df_feat[total_col]\n",
    "    created_cols += [total_col, f\"prop_{mcol}\", f\"prop_{fcol}\"]\n",
    "\n",
    "# Date parts\n",
    "date_cols = [c for c in df_feat.columns if np.issubdtype(df_feat[c].dtype, np.datetime64)]\n",
    "for c in date_cols:\n",
    "    df_feat[f\"{c}_year\"] = df_feat[c].dt.year\n",
    "    df_feat[f\"{c}_month\"] = df_feat[c].dt.month\n",
    "    df_feat[f\"{c}_quarter\"] = df_feat[c].dt.quarter\n",
    "    created_cols += [f\"{c}_year\", f\"{c}_month\", f\"{c}_quarter\"]\n",
    "\n",
    "# Winsorized copies\n",
    "for c in df_feat.select_dtypes(include=[np.number]).columns:\n",
    "    wz = f\"{c}_wz\"\n",
    "    df_feat[wz] = winsorize_series(df_feat[c])\n",
    "    created_cols.append(wz)\n",
    "\n",
    "print(f\"Created features: {len(created_cols)}\")\n",
    "df_feat.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8211e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet = bool(CFG.get(\"data\", {}).get(\"write_parquet\", True))\n",
    "parquet_compression = CFG.get(\"data\", {}).get(\"parquet_compression\", \"snappy\")\n",
    "\n",
    "out_csv = PROCESSED_DIR / f\"{RAW_CSV.stem}.features.csv\"\n",
    "df_feat.to_csv(out_csv, index=False)\n",
    "\n",
    "out_parquet = None\n",
    "if write_parquet:\n",
    "    out_parquet = PROCESSED_DIR / f\"{RAW_CSV.stem}.features.parquet\"\n",
    "    df_feat.to_parquet(out_parquet, index=False, compression=parquet_compression)\n",
    "\n",
    "report_path = REPORTS_DIR / \"eda_report.md\"\n",
    "lines = []\n",
    "lines.append(f\"# EDA Report — generated {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "lines.append(\"\")\n",
    "lines.append(f\"- Source: `{RAW_CSV}`\")\n",
    "lines.append(f\"- Shape: {df.shape[0]} x {df.shape[1]}\")\n",
    "lines.append(f\"- Numeric columns: {len([c for c in df.select_dtypes(include=[np.number]).columns])}\")\n",
    "lines.append(f\"- Categorical (incl. low-card): {len([c for c in df.columns if c not in df.select_dtypes(include=[np.number]).columns])}\")\n",
    "if pop_col: lines.append(f\"- Population column: `{pop_col}`\")\n",
    "if created_cols:\n",
    "    preview = \", \".join(created_cols[:15]) + (\" ...\" if len(created_cols) > 15 else \"\")\n",
    "    lines.append(f\"- Created features: {preview}\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## Figures\")\n",
    "for p in sorted((REPORTS_DIR / \"figures\" / \"0_1_eda\").glob(\"*.png\")):\n",
    "    lines.append(f\"- {p.relative_to(PROJECT_DIR)}\")\n",
    "report_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "# Run metadata (for traceability / MLflow-friendly)\n",
    "run_meta = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"seed\": SEED,\n",
    "    \"inputs\": {\"raw_csv\": str(RAW_CSV)},\n",
    "    \"outputs\": {\n",
    "        \"csv\": str(out_csv),\n",
    "        \"parquet\": str(out_parquet) if out_parquet else None,\n",
    "        \"report\": str(report_path),\n",
    "        \"fig_dir\": str(FIG_DIR),\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"project\": CFG.get(\"project\"),\n",
    "        \"csv_options\": CFG.get(\"csv_options\"),\n",
    "        \"paths\": CFG.get(\"paths\"),\n",
    "        \"data\": CFG.get(\"data\"),\n",
    "    },\n",
    "}\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "meta_path = ARTIFACTS_DIR / \"eda_run_meta.json\"\n",
    "meta_path.write_text(json.dumps(run_meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "(out_csv, out_parquet, report_path, meta_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309fcfa4",
   "metadata": {},
   "source": [
    "# Cell 11 — Next steps (Markdown)\n",
    "\n",
    "- Promote Cells 5–9 to `src/features/build_features.py` (config-driven).\n",
    "- Add `make eda` target + pytest data checks (schema, ranges, missing).\n",
    "- If `paths.schema` exists, validate dtypes and allowed categories against it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
